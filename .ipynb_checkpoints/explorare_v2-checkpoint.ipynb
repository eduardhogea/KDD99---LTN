{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5c5ec92-5dbe-45ea-b575-800568605af3",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34c5925e-32be-4108-afd3-57d144b3fa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logictensornetworks as ltn\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250efae2-5a1c-4922-9a1d-cfa6a0f98bff",
   "metadata": {},
   "source": [
    "# Dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2cc32e28-2707-4bd0-ac2a-118486a818db",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "df = pd.read_csv(\"kddcup99.csv\", skipinitialspace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "286f1102-1443-453e-af3b-df7cd19601c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(494020, 42)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape #numar de linii si coloane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23066d9d-7d8d-4c86-8705-2d8b05a13e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145585, 42)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(keep= 'first', inplace=True) #eliminarea dublurilor liniilor\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a72b1a2b-d288-4e10-8b23-4d8c94f32d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>lnum_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>145585.000000</td>\n",
       "      <td>1.455850e+05</td>\n",
       "      <td>1.455850e+05</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>132.026088</td>\n",
       "      <td>7.995752e+03</td>\n",
       "      <td>2.859788e+03</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.020201</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.100175</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.491486</td>\n",
       "      <td>0.026177</td>\n",
       "      <td>...</td>\n",
       "      <td>181.469423</td>\n",
       "      <td>129.935570</td>\n",
       "      <td>0.553226</td>\n",
       "      <td>0.061389</td>\n",
       "      <td>0.092826</td>\n",
       "      <td>0.019048</td>\n",
       "      <td>0.291599</td>\n",
       "      <td>0.290980</td>\n",
       "      <td>0.110464</td>\n",
       "      <td>0.107676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1224.161209</td>\n",
       "      <td>1.820390e+06</td>\n",
       "      <td>6.081000e+04</td>\n",
       "      <td>0.011720</td>\n",
       "      <td>0.239369</td>\n",
       "      <td>0.010150</td>\n",
       "      <td>1.426803</td>\n",
       "      <td>0.028586</td>\n",
       "      <td>0.499929</td>\n",
       "      <td>3.311384</td>\n",
       "      <td>...</td>\n",
       "      <td>99.097396</td>\n",
       "      <td>114.714717</td>\n",
       "      <td>0.456236</td>\n",
       "      <td>0.147021</td>\n",
       "      <td>0.241124</td>\n",
       "      <td>0.060410</td>\n",
       "      <td>0.452493</td>\n",
       "      <td>0.453448</td>\n",
       "      <td>0.306098</td>\n",
       "      <td>0.304221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.470000e+02</td>\n",
       "      <td>1.050000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.880000e+02</td>\n",
       "      <td>1.164000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>58329.000000</td>\n",
       "      <td>6.933756e+08</td>\n",
       "      <td>5.155468e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>884.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            duration     src_bytes     dst_bytes           land  \\\n",
       "count  145585.000000  1.455850e+05  1.455850e+05  145585.000000   \n",
       "mean      132.026088  7.995752e+03  2.859788e+03       0.000137   \n",
       "std      1224.161209  1.820390e+06  6.081000e+04       0.011720   \n",
       "min         0.000000  0.000000e+00  0.000000e+00       0.000000   \n",
       "25%         0.000000  0.000000e+00  0.000000e+00       0.000000   \n",
       "50%         0.000000  1.470000e+02  1.050000e+02       0.000000   \n",
       "75%         0.000000  2.880000e+02  1.164000e+03       0.000000   \n",
       "max     58329.000000  6.933756e+08  5.155468e+06       1.000000   \n",
       "\n",
       "       wrong_fragment         urgent            hot  num_failed_logins  \\\n",
       "count   145585.000000  145585.000000  145585.000000      145585.000000   \n",
       "mean         0.020201       0.000048       0.100175           0.000515   \n",
       "std          0.239369       0.010150       1.426803           0.028586   \n",
       "min          0.000000       0.000000       0.000000           0.000000   \n",
       "25%          0.000000       0.000000       0.000000           0.000000   \n",
       "50%          0.000000       0.000000       0.000000           0.000000   \n",
       "75%          0.000000       0.000000       0.000000           0.000000   \n",
       "max          3.000000       3.000000      30.000000           5.000000   \n",
       "\n",
       "           logged_in  lnum_compromised  ...  dst_host_count  \\\n",
       "count  145585.000000     145585.000000  ...   145585.000000   \n",
       "mean        0.491486          0.026177  ...      181.469423   \n",
       "std         0.499929          3.311384  ...       99.097396   \n",
       "min         0.000000          0.000000  ...        0.000000   \n",
       "25%         0.000000          0.000000  ...       78.000000   \n",
       "50%         0.000000          0.000000  ...      255.000000   \n",
       "75%         1.000000          0.000000  ...      255.000000   \n",
       "max         1.000000        884.000000  ...      255.000000   \n",
       "\n",
       "       dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "count       145585.000000           145585.000000           145585.000000   \n",
       "mean           129.935570                0.553226                0.061389   \n",
       "std            114.714717                0.456236                0.147021   \n",
       "min              0.000000                0.000000                0.000000   \n",
       "25%             12.000000                0.050000                0.000000   \n",
       "50%            117.000000                0.770000                0.020000   \n",
       "75%            255.000000                1.000000                0.070000   \n",
       "max            255.000000                1.000000                1.000000   \n",
       "\n",
       "       dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "count                145585.000000                145585.000000   \n",
       "mean                      0.092826                     0.019048   \n",
       "std                       0.241124                     0.060410   \n",
       "min                       0.000000                     0.000000   \n",
       "25%                       0.000000                     0.000000   \n",
       "50%                       0.000000                     0.000000   \n",
       "75%                       0.030000                     0.020000   \n",
       "max                       1.000000                     1.000000   \n",
       "\n",
       "       dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "count         145585.000000             145585.000000         145585.000000   \n",
       "mean               0.291599                  0.290980              0.110464   \n",
       "std                0.452493                  0.453448              0.306098   \n",
       "min                0.000000                  0.000000              0.000000   \n",
       "25%                0.000000                  0.000000              0.000000   \n",
       "50%                0.000000                  0.000000              0.000000   \n",
       "75%                1.000000                  1.000000              0.000000   \n",
       "max                1.000000                  1.000000              1.000000   \n",
       "\n",
       "       dst_host_srv_rerror_rate  \n",
       "count             145585.000000  \n",
       "mean                   0.107676  \n",
       "std                    0.304221  \n",
       "min                    0.000000  \n",
       "25%                    0.000000  \n",
       "50%                    0.000000  \n",
       "75%                    0.000000  \n",
       "max                    1.000000  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd85ce89-c5e4-40fb-b382-020e4e2f2bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1) #shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81212d18-52f7-4b0b-a414-f735732cba82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_cols = list(df.columns)[1:-1]\n",
    "# target_col = 'label'\n",
    "# numeric_cols = df.select_dtypes(include=np.number).columns.tolist()[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba0e7e62-9023-4cb3-8058-fb69d81947cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# scaler.fit(df[numeric_cols])\n",
    "# df[numeric_cols] = scaler.transform(df[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99e2791b-3246-4bc2-87f6-c5ee53d6085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# le = LabelEncoder()\n",
    "\n",
    "# target = df['label']\n",
    "# df['label'] = le.fit_transform(target)\n",
    "# df['protocol_type'] = le.fit_transform(df['protocol_type'])\n",
    "# df['service'] = le.fit_transform(df['service'])\n",
    "# df['flag'] = le.fit_transform(df['flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b1d0dbb-1008-4ff6-9ad0-b79a1efbbba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[['duration','dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot','num_failed_logins', 'logged_in', 'lnum_compromised', 'lroot_shell','lsu_attempted', 'lnum_root', 'lnum_file_creations', 'lnum_shells','lnum_access_files', 'lnum_outbound_cmds', 'is_host_login','is_guest_login', 'count', 'srv_count', 'serror_rate','srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate','diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count','dst_host_srv_count', 'dst_host_same_srv_rate','dst_host_diff_srv_rate', 'dst_host_same_src_port_rate','dst_host_srv_diff_host_rate', 'dst_host_serror_rate','dst_host_srv_serror_rate', 'dst_host_rerror_rate','dst_host_srv_rerror_rate']]\n",
    "\n",
    "label_srcbytes = df['src_bytes']\n",
    "label_diffsrvrate = df['diff_srv_rate']\n",
    "label_label=df['label']\n",
    "batch_size=64\n",
    "\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((features[:110000],label_srcbytes[:110000],label_diffsrvrate[:110000], label_label[:110000])).batch(batch_size)\n",
    "ds_test = tf.data.Dataset.from_tensor_slices((features[110000:],label_srcbytes[110000:],label_diffsrvrate[110000:], label_label[110000:])).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "60b32da3-f99c-457e-8520-fc04a68ff4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 37), dtype=float64, numpy=\n",
       "array([[0.00000000e+00, 1.82330683e-05, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 6.00000000e-02, 0.00000000e+00],\n",
       "       [2.35731797e-02, 2.03667252e-05, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 6.55808551e-04, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [3.42882614e-05, 2.85134153e-05, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 2.57978519e-05, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 9.72753589e-04, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26397801-33a9-4e3f-8de1-8bb2ef66820f",
   "metadata": {},
   "source": [
    "# Creare model\n",
    "\n",
    "### Predicate\n",
    "\n",
    "| index | class | \n",
    "| --- | --- |\n",
    "| 0 | normal |\n",
    "| 1 | smurf |\n",
    "| 2 | neptune |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f15619b-ec0c-4938-861a-b44965aee1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.Model):\n",
    "    \"\"\"Model that returns logits.\"\"\"\n",
    "    def __init__(self, n_classes, hidden_layer_sizes=(16,16,8)):\n",
    "        super(MLP, self).__init__()\n",
    "        self.denses = [tf.keras.layers.Dense(s, activation=\"elu\") for s in hidden_layer_sizes]\n",
    "        self.dense_class = tf.keras.layers.Dense(n_classes)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        for dense in self.denses:\n",
    "            x = dense(x)\n",
    "        return self.dense_class(x)\n",
    "\n",
    "logits_model = MLP(5)\n",
    "p = ltn.Predicate(ltn.utils.LogitsToPredicateModel(logits_model,single_label=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9175e09d-b2dc-480d-95e0-121d9d58c356",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_normal = ltn.Constant(0, trainable=False)\n",
    "class_smurf = ltn.Constant(1, trainable=False)\n",
    "class_neptune = ltn.Constant(2, trainable=False)\n",
    "# class_bytes = ltn.Constant(3, trainable=False)\n",
    "# class_srv = ltn.Constant(4, trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c179e7a-0658-4a62-9464-796aaad860d6",
   "metadata": {},
   "source": [
    "# Logica si axiomele\n",
    "```\n",
    "forall x_normal: C(x_normal,normal): all the non-attacks should have label normal\n",
    "forall x_smurf: C(x_smurf,smurf): all the smurf attacks should have label smurf\n",
    "forall x_normal: C(x_neptune,neptune): all the neptune attacks should have label neptune\n",
    "\n",
    "forall x: ~(C(x,normal) & C(x,smurf)): if an example x is labelled as normal, it cannot be labelled as smurf too;\n",
    "forall x: ~(C(x,normal) & C(x,neptune)): if an example x is labelled as normal, it cannot be labelled as neptune too;\n",
    "forall x: ~(C(x,neptune) & C(x,smurf)): if an example x is labelled as neptune, it cannot be labelled as smurf too;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73fd4aa8-a4ef-4cfe-83be-fa54765500ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Not = ltn.Wrapper_Connective(ltn.fuzzy_ops.Not_Std())\n",
    "And = ltn.Wrapper_Connective(ltn.fuzzy_ops.And_Prod())\n",
    "Or = ltn.Wrapper_Connective(ltn.fuzzy_ops.Or_ProbSum())\n",
    "Implies = ltn.Wrapper_Connective(ltn.fuzzy_ops.Implies_Reichenbach())\n",
    "Equiv = ltn.Wrapper_Connective(ltn.fuzzy_ops.Equiv(ltn.fuzzy_ops.And_Prod(),ltn.fuzzy_ops.Implies_Reichenbach()))\n",
    "Forall = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMeanError(p=4),semantics=\"forall\")\n",
    "Exists = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMean(p=6),semantics=\"exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b774e1b8-9148-4769-ba51-495d19a86387",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_aggregator = ltn.Wrapper_Formula_Aggregator(ltn.fuzzy_ops.Aggreg_pMeanError(p=4))\n",
    "\n",
    "@tf.function\n",
    "def axioms(features,label_srcbytes,label_diffsrvrate,label_label):\n",
    "    x = ltn.Variable(\"x\",features)\n",
    "    x_normal = ltn.Variable(\"x_normal\",features[label_label==\"normal\"])\n",
    "    x_smurf = ltn.Variable(\"x_smurf\",features[label_label==\"smurf\"])\n",
    "    x_neptune = ltn.Variable(\"x_neptune\",features[label_label==\"neptune\"])\n",
    "    #x_bytes = ltn.Variable(\"x_bytes\",features[label_srcbytes])\n",
    "    #x_diffsrvrate = ltn.Variable(\"x_diffsrvrate\",features[label_diffsrvrate])\n",
    "    \n",
    "    axioms = [\n",
    "        Forall(x_normal, p([x_normal,class_normal])),\n",
    "        Forall(x_smurf, p([x_smurf,class_smurf])),\n",
    "        Forall(x_neptune, p([x_neptune,class_neptune])),\n",
    "\n",
    "        Forall(x,Not(And(p([x,class_normal]),p([x,class_smurf])))),\n",
    "        Forall(x,Not(And(p([x,class_normal]),p([x,class_neptune])))),\n",
    "        Forall(x,Not(And(p([x,class_neptune]),p([x,class_smurf])))),\n",
    "        \n",
    "    ]\n",
    "    sat_level = formula_aggregator(axioms).tensor\n",
    "    return sat_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83aabb19-155c-4f10-8a58-f87747eb7978",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/var/folders/9m/k3vyv4317cz56g6f681k4jnm0000gn/T/ipykernel_85207/980215655.py\", line 6, in axioms  *\n        x_normal = ltn.Variable(\"x_normal\",features[label_label==\"normal\"])\n\n    TypeError: Expected int64, but got normal of type 'str'.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9m/k3vyv4317cz56g6f681k4jnm0000gn/T/ipykernel_85207/75226228.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_srcbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_diffsrvrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_label\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mds_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initial sat level %.5f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0maxioms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_srcbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_diffsrvrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/var/folders/9m/k3vyv4317cz56g6f681k4jnm0000gn/T/ipykernel_85207/980215655.py\", line 6, in axioms  *\n        x_normal = ltn.Variable(\"x_normal\",features[label_label==\"normal\"])\n\n    TypeError: Expected int64, but got normal of type 'str'.\n"
     ]
    }
   ],
   "source": [
    "for features, label_srcbytes, label_diffsrvrate, label_label in ds_train:\n",
    "    print(\"Initial sat level %.5f\"%axioms(features, label_srcbytes, label_diffsrvrate, label_label))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cdd35a-fe99-4d93-bf0d-9dace145880a",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0f3618d-ddea-433f-a6a6-5875a55d8ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = {\n",
    "    'train_sat_kb': tf.keras.metrics.Mean(name='train_sat_kb'),\n",
    "    'test_sat_kb': tf.keras.metrics.Mean(name='test_sat_kb'),\n",
    "    'train_accuracy': tf.keras.metrics.Mean(name=\"train_accuracy\"),\n",
    "    'test_accuracy': tf.keras.metrics.Mean(name=\"test_accuracy\"),\n",
    "    'test_sat_phi1': tf.keras.metrics.Mean(name='test_sat_phi1'),\n",
    "    'test_sat_phi2': tf.keras.metrics.Mean(name='test_sat_phi2'),\n",
    "    'test_sat_phi3': tf.keras.metrics.Mean(name='test_sat_phi3')\n",
    "}\n",
    "\n",
    "@tf.function()\n",
    "def sat_phi1(features):\n",
    "    x = ltn.Variable(\"x\",features)\n",
    "    phi1 = Forall(x, Implies(p([x,class_udp]),Not(p([x,class_tcp]))),p=5)\n",
    "    return phi1.tensor\n",
    "\n",
    "@tf.function()\n",
    "def sat_phi2(features):\n",
    "    x = ltn.Variable(\"x\",features)\n",
    "    phi2 = Forall(x, Implies(p([x,class_udp]),p([x,class_tcp])),p=5)\n",
    "    return phi2.tensor\n",
    "\n",
    "@tf.function()\n",
    "def sat_phi3(features):\n",
    "    x = ltn.Variable(\"x\",features)\n",
    "    phi3 = Forall(x, Implies(p([x,class_tcp]),p([x,class_sf])),p=5)\n",
    "    return phi3.tensor\n",
    "\n",
    "def multilabel_hamming_loss(y_true, y_pred, threshold=0.5,from_logits=False):\n",
    "    if from_logits:\n",
    "        y_pred = tf.math.sigmoid(y_pred)\n",
    "    y_pred = y_pred > threshold\n",
    "    y_true = tf.cast(y_true, tf.int32)\n",
    "    y_pred = tf.cast(y_pred, tf.int32)\n",
    "    nonzero = tf.cast(tf.math.count_nonzero(y_true-y_pred,axis=-1),tf.float32)\n",
    "    return nonzero/y_true.get_shape()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29091238-591b-45fd-954c-33252dfb1381",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "@tf.function\n",
    "def train_step(features, label_protocol_type, label_flag):\n",
    "    # sat and update\n",
    "    with tf.GradientTape() as tape:\n",
    "        sat = axioms(features, label_protocol_type, label_flag)\n",
    "        loss = 1.-sat\n",
    "    gradients = tape.gradient(loss, p.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, p.trainable_variables))\n",
    "    metrics_dict['train_sat_kb'](sat)\n",
    "    # accuracy\n",
    "    predictions = logits_model(features)\n",
    "    label_tcp = (label_protocol_type == \"TCP\")\n",
    "    label_icmp = (label_protocol_type == \"ICMP\")\n",
    "    label_udp = (label_protocol_type == \"UDP\")\n",
    "    label_sf = (label_flag == \"SF\")\n",
    "    label_s1 = (label_flag == \"S1\")\n",
    "    label_rej = (label_flag == \"REJ\")\n",
    "    label_s2 = (label_flag == \"S2\")\n",
    "    label_s0 = (label_flag == \"S0\")\n",
    "    label_s3 = (label_flag == \"S3\")\n",
    "    label_rsto = (label_flag == \"RSTO\")\n",
    "    label_rstr = (label_flag == \"RSTR\")\n",
    "    label_rstos0 = (label_flag == \"RSTOS0\")\n",
    "    label_oth = (label_flag == \"OTH\")\n",
    "    label_sh = (label_flag == \"SH\")\n",
    "    \n",
    "\n",
    "    onehot = tf.stack([label_tcp,label_icmp,label_udp,label_sf,label_s1,label_rej,label_s2,label_s0,label_s3,label_rsto,label_rstr,label_rstos0,label_oth,label_sh],axis=-1)\n",
    "    #onehot = tf.stack([label_tcp,label_icmp,label_udp,label_sf],axis=-1)\n",
    "    metrics_dict['train_accuracy'](1-multilabel_hamming_loss(onehot,predictions,from_logits=True))\n",
    "    \n",
    "@tf.function\n",
    "def test_step(features, label_protocol_type, label_flag):\n",
    "    # sat\n",
    "    sat_kb = axioms(features, label_protocol_type, label_flag)\n",
    "    metrics_dict['test_sat_kb'](sat_kb)\n",
    "    metrics_dict['test_sat_phi1'](sat_phi1(features))\n",
    "    metrics_dict['test_sat_phi2'](sat_phi2(features))\n",
    "    metrics_dict['test_sat_phi3'](sat_phi3(features))\n",
    "    # accuracy\n",
    "    predictions = logits_model(features)\n",
    "    label_tcp = (label_protocol_type == \"TCP\")\n",
    "    label_icmp = (label_protocol_type == \"ICMP\")\n",
    "    label_udp = (label_protocol_type == \"UDP\")\n",
    "    label_sf = (label_flag == \"SF\")\n",
    "    label_s1 = (label_flag == \"S1\")\n",
    "    label_rej = (label_flag == \"REJ\")\n",
    "    label_s2 = (label_flag == \"S2\")\n",
    "    label_s0 = (label_flag == \"S0\")\n",
    "    label_s3 = (label_flag == \"S3\")\n",
    "    label_rsto = (label_flag == \"RSTO\")\n",
    "    label_rstr = (label_flag == \"RSTR\")\n",
    "    label_rstos0 = (label_flag == \"RSTOS0\")\n",
    "    label_oth = (label_flag == \"OTH\")\n",
    "    label_sh = (label_flag == \"SH\")\n",
    "    onehot = tf.stack([label_tcp,label_icmp,label_udp,label_sf,label_s1,label_rej,label_s2,label_s0,label_s3,label_rsto,label_rstr,label_rstos0,label_oth,label_sh],axis=-1)\n",
    "    #onehot = tf.stack([label_tcp,label_icmp,label_udp,label_sf],axis=-1)\n",
    "    metrics_dict['test_accuracy'](1-multilabel_hamming_loss(onehot,predictions,from_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d8861a1-1a0e-4e9d-b4eb-5447da40c483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def train(\n",
    "        epochs,\n",
    "        metrics_dict, \n",
    "        ds_train, \n",
    "        ds_test, \n",
    "        train_step, \n",
    "        test_step,\n",
    "        track_metrics=1,\n",
    "        csv_path=None,\n",
    "        scheduled_parameters=defaultdict(lambda : {})\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        epochs: int, number of training epochs.\n",
    "        metrics_dict: dict, {\"metrics_label\": tf.keras.metrics instance}.\n",
    "        ds_train: iterable dataset, e.g. using tf.data.Dataset.\n",
    "        ds_test: iterable dataset, e.g. using tf.data.Dataset.\n",
    "        train_step: callable function. the arguments passed to the function\n",
    "            are the itered elements of ds_train.\n",
    "        test_step: callable function. the arguments passed to the function\n",
    "            are the itered elements of ds_test.\n",
    "        csv_path: (optional) path to create a csv file, to save the metrics.\n",
    "        scheduled_parameters: (optional) a dictionary that returns kwargs for\n",
    "            the train_step and test_step functions, for each epoch.\n",
    "            Call using scheduled_parameters[epoch].\n",
    "    \"\"\"\n",
    "    template = \"Epoch {}\"\n",
    "    for metrics_label in metrics_dict.keys():\n",
    "        template += \", %s: {:.4f}\" % metrics_label\n",
    "    if csv_path is not None:\n",
    "        csv_file = open(csv_path,\"w+\")\n",
    "        headers = \",\".join([\"Epoch\"]+list(metrics_dict.keys()))\n",
    "        csv_template = \",\".join([\"{}\" for _ in range(len(metrics_dict)+1)])\n",
    "        csv_file.write(headers+\"\\n\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for metrics in metrics_dict.values():\n",
    "            metrics.reset_states()\n",
    "\n",
    "        for batch_elements in ds_train:\n",
    "            train_step(*batch_elements,**scheduled_parameters[epoch])\n",
    "        for batch_elements in ds_test:\n",
    "            test_step(*batch_elements,**scheduled_parameters[epoch])\n",
    "\n",
    "        metrics_results = [metrics.result() for metrics in metrics_dict.values()]\n",
    "        if epoch%track_metrics == 0:\n",
    "            print(template.format(epoch,*metrics_results))\n",
    "        if csv_path is not None:\n",
    "            csv_file.write(csv_template.format(epoch,*metrics_results)+\"\\n\")\n",
    "            csv_file.flush()\n",
    "    if csv_path is not None:\n",
    "        csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec5172a5-8eeb-40a9-831a-763e46d3cd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 21:40:07.122021: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-25 21:41:34.089791: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-25 21:41:45.302566: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train_sat_kb: 0.8647, test_sat_kb: 0.9738, train_accuracy: 0.4954, test_accuracy: 0.5004, test_sat_phi1: 0.9999, test_sat_phi2: 0.9998, test_sat_phi3: 0.9999\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "train(\n",
    "    EPOCHS,\n",
    "    metrics_dict,\n",
    "    ds_train,\n",
    "    ds_test,\n",
    "    train_step,\n",
    "    test_step,\n",
    "    csv_path=\"results.csv\",\n",
    "    track_metrics=20\n",
    ")\n",
    "\n",
    "end_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9964a478-17d7-4fb4-b4eb-af4a8c62d3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 2023.613s to run\n"
     ]
    }
   ],
   "source": [
    "print(\"It took\", end =\" \")\n",
    "total_time = round(end_time-start_time,3)\n",
    "print(total_time , end =\"\")\n",
    "print(\"s to run\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
