{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5c5ec92-5dbe-45ea-b575-800568605af3",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34c5925e-32be-4108-afd3-57d144b3fa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logictensornetworks as ltn\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250efae2-5a1c-4922-9a1d-cfa6a0f98bff",
   "metadata": {},
   "source": [
    "# Dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cc32e28-2707-4bd0-ac2a-118486a818db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"kddcup99.csv\", skipinitialspace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "286f1102-1443-453e-af3b-df7cd19601c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(494020, 42)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape #numar de linii si coloane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23066d9d-7d8d-4c86-8705-2d8b05a13e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145585, 42)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(keep= 'first', inplace=True) #eliminarea dublurilor liniilor\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a72b1a2b-d288-4e10-8b23-4d8c94f32d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>lnum_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>145585.000000</td>\n",
       "      <td>1.455850e+05</td>\n",
       "      <td>1.455850e+05</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>132.026088</td>\n",
       "      <td>7.995752e+03</td>\n",
       "      <td>2.859788e+03</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.020201</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.100175</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.491486</td>\n",
       "      <td>0.026177</td>\n",
       "      <td>...</td>\n",
       "      <td>181.469423</td>\n",
       "      <td>129.935570</td>\n",
       "      <td>0.553226</td>\n",
       "      <td>0.061389</td>\n",
       "      <td>0.092826</td>\n",
       "      <td>0.019048</td>\n",
       "      <td>0.291599</td>\n",
       "      <td>0.290980</td>\n",
       "      <td>0.110464</td>\n",
       "      <td>0.107676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1224.161209</td>\n",
       "      <td>1.820390e+06</td>\n",
       "      <td>6.081000e+04</td>\n",
       "      <td>0.011720</td>\n",
       "      <td>0.239369</td>\n",
       "      <td>0.010150</td>\n",
       "      <td>1.426803</td>\n",
       "      <td>0.028586</td>\n",
       "      <td>0.499929</td>\n",
       "      <td>3.311384</td>\n",
       "      <td>...</td>\n",
       "      <td>99.097396</td>\n",
       "      <td>114.714717</td>\n",
       "      <td>0.456236</td>\n",
       "      <td>0.147021</td>\n",
       "      <td>0.241124</td>\n",
       "      <td>0.060410</td>\n",
       "      <td>0.452493</td>\n",
       "      <td>0.453448</td>\n",
       "      <td>0.306098</td>\n",
       "      <td>0.304221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.470000e+02</td>\n",
       "      <td>1.050000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.880000e+02</td>\n",
       "      <td>1.164000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>58329.000000</td>\n",
       "      <td>6.933756e+08</td>\n",
       "      <td>5.155468e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>884.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            duration     src_bytes     dst_bytes           land  \\\n",
       "count  145585.000000  1.455850e+05  1.455850e+05  145585.000000   \n",
       "mean      132.026088  7.995752e+03  2.859788e+03       0.000137   \n",
       "std      1224.161209  1.820390e+06  6.081000e+04       0.011720   \n",
       "min         0.000000  0.000000e+00  0.000000e+00       0.000000   \n",
       "25%         0.000000  0.000000e+00  0.000000e+00       0.000000   \n",
       "50%         0.000000  1.470000e+02  1.050000e+02       0.000000   \n",
       "75%         0.000000  2.880000e+02  1.164000e+03       0.000000   \n",
       "max     58329.000000  6.933756e+08  5.155468e+06       1.000000   \n",
       "\n",
       "       wrong_fragment         urgent            hot  num_failed_logins  \\\n",
       "count   145585.000000  145585.000000  145585.000000      145585.000000   \n",
       "mean         0.020201       0.000048       0.100175           0.000515   \n",
       "std          0.239369       0.010150       1.426803           0.028586   \n",
       "min          0.000000       0.000000       0.000000           0.000000   \n",
       "25%          0.000000       0.000000       0.000000           0.000000   \n",
       "50%          0.000000       0.000000       0.000000           0.000000   \n",
       "75%          0.000000       0.000000       0.000000           0.000000   \n",
       "max          3.000000       3.000000      30.000000           5.000000   \n",
       "\n",
       "           logged_in  lnum_compromised  ...  dst_host_count  \\\n",
       "count  145585.000000     145585.000000  ...   145585.000000   \n",
       "mean        0.491486          0.026177  ...      181.469423   \n",
       "std         0.499929          3.311384  ...       99.097396   \n",
       "min         0.000000          0.000000  ...        0.000000   \n",
       "25%         0.000000          0.000000  ...       78.000000   \n",
       "50%         0.000000          0.000000  ...      255.000000   \n",
       "75%         1.000000          0.000000  ...      255.000000   \n",
       "max         1.000000        884.000000  ...      255.000000   \n",
       "\n",
       "       dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "count       145585.000000           145585.000000           145585.000000   \n",
       "mean           129.935570                0.553226                0.061389   \n",
       "std            114.714717                0.456236                0.147021   \n",
       "min              0.000000                0.000000                0.000000   \n",
       "25%             12.000000                0.050000                0.000000   \n",
       "50%            117.000000                0.770000                0.020000   \n",
       "75%            255.000000                1.000000                0.070000   \n",
       "max            255.000000                1.000000                1.000000   \n",
       "\n",
       "       dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "count                145585.000000                145585.000000   \n",
       "mean                      0.092826                     0.019048   \n",
       "std                       0.241124                     0.060410   \n",
       "min                       0.000000                     0.000000   \n",
       "25%                       0.000000                     0.000000   \n",
       "50%                       0.000000                     0.000000   \n",
       "75%                       0.030000                     0.020000   \n",
       "max                       1.000000                     1.000000   \n",
       "\n",
       "       dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "count         145585.000000             145585.000000         145585.000000   \n",
       "mean               0.291599                  0.290980              0.110464   \n",
       "std                0.452493                  0.453448              0.306098   \n",
       "min                0.000000                  0.000000              0.000000   \n",
       "25%                0.000000                  0.000000              0.000000   \n",
       "50%                0.000000                  0.000000              0.000000   \n",
       "75%                1.000000                  1.000000              0.000000   \n",
       "max                1.000000                  1.000000              1.000000   \n",
       "\n",
       "       dst_host_srv_rerror_rate  \n",
       "count             145585.000000  \n",
       "mean                   0.107676  \n",
       "std                    0.304221  \n",
       "min                    0.000000  \n",
       "25%                    0.000000  \n",
       "50%                    0.000000  \n",
       "75%                    0.000000  \n",
       "max                    1.000000  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd85ce89-c5e4-40fb-b382-020e4e2f2bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1) #shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b1d0dbb-1008-4ff6-9ad0-b79a1efbbba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-03 22:11:19.781976: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-01-03 22:11:19.782475: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "features = df[['duration', 'src_bytes','dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot','num_failed_logins', 'logged_in', 'lnum_compromised', 'lroot_shell','lsu_attempted', 'lnum_root', 'lnum_file_creations', 'lnum_shells','lnum_access_files', 'lnum_outbound_cmds', 'is_host_login','is_guest_login', 'count', 'srv_count', 'serror_rate','srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate','diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count','dst_host_srv_count', 'dst_host_same_srv_rate','dst_host_diff_srv_rate', 'dst_host_same_src_port_rate','dst_host_srv_diff_host_rate', 'dst_host_serror_rate','dst_host_srv_serror_rate', 'dst_host_rerror_rate','dst_host_srv_rerror_rate']]\n",
    "label_protocol_type = df['protocol_type']\n",
    "label_flag = df['flag']\n",
    "batch_size=64\n",
    "\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((features[:160],label_protocol_type[:160],label_flag[:160])).batch(batch_size)\n",
    "ds_test = tf.data.Dataset.from_tensor_slices((features[160:],label_protocol_type[160:],label_flag[160:])).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26397801-33a9-4e3f-8de1-8bb2ef66820f",
   "metadata": {},
   "source": [
    "# Creare model\n",
    "\n",
    "### Predicate\n",
    "\n",
    "| index | class | \n",
    "| --- | --- |\n",
    "| 0 | TCP |\n",
    "| 1 | ICMP |\n",
    "| 2 | UDP |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f15619b-ec0c-4938-861a-b44965aee1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.Model):\n",
    "    \"\"\"Model that returns logits.\"\"\"\n",
    "    def __init__(self, n_classes, hidden_layer_sizes=(16,16,8)):\n",
    "        super(MLP, self).__init__()\n",
    "        self.denses = [tf.keras.layers.Dense(s, activation=\"elu\") for s in hidden_layer_sizes]\n",
    "        self.dense_class = tf.keras.layers.Dense(n_classes)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        for dense in self.denses:\n",
    "            x = dense(x)\n",
    "        return self.dense_class(x)\n",
    "\n",
    "logits_model = MLP(3)\n",
    "p = ltn.Predicate(ltn.utils.LogitsToPredicateModel(logits_model,single_label=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9175e09d-b2dc-480d-95e0-121d9d58c356",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_tcp = ltn.Constant(0, trainable=False)\n",
    "class_icmp = ltn.Constant(1, trainable=False)\n",
    "class_udp = ltn.Constant(2, trainable=False)\n",
    "# class_sf = ltn.Constant(3, trainable=False)\n",
    "# class_s1 = ltn.Constant(4, trainable=False)\n",
    "# class_rej = ltn.Constant(5, trainable=False)\n",
    "# class_s2 = ltn.Constant(6, trainable=False)\n",
    "# class_s0 = ltn.Constant(7, trainable=False)\n",
    "# class_s3 = ltn.Constant(8, trainable=False)\n",
    "# class_rsto = ltn.Constant(9, trainable=False)\n",
    "# class_rstr = ltn.Constant(10, trainable=False)\n",
    "# class_rstos0 = ltn.Constant(11, trainable=False)\n",
    "# class_oth = ltn.Constant(12, trainable=False)\n",
    "# class_sh = ltn.Constant(13, trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c179e7a-0658-4a62-9464-796aaad860d6",
   "metadata": {},
   "source": [
    "# Logica si axiomele\n",
    "```\n",
    "forall x_tcp: C(x_tcp,tcp)\n",
    "forall x_icmp: C(x_icmp,icmp)\n",
    "forall x_udp: C(x_udp,udp)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73fd4aa8-a4ef-4cfe-83be-fa54765500ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Not = ltn.Wrapper_Connective(ltn.fuzzy_ops.Not_Std())\n",
    "And = ltn.Wrapper_Connective(ltn.fuzzy_ops.And_Prod())\n",
    "Or = ltn.Wrapper_Connective(ltn.fuzzy_ops.Or_ProbSum())\n",
    "Implies = ltn.Wrapper_Connective(ltn.fuzzy_ops.Implies_Reichenbach())\n",
    "Equiv = ltn.Wrapper_Connective(ltn.fuzzy_ops.Equiv(ltn.fuzzy_ops.And_Prod(),ltn.fuzzy_ops.Implies_Reichenbach()))\n",
    "Forall = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMeanError(p=4),semantics=\"forall\")\n",
    "Exists = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMean(p=6),semantics=\"exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b774e1b8-9148-4769-ba51-495d19a86387",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_aggregator = ltn.Wrapper_Formula_Aggregator(ltn.fuzzy_ops.Aggreg_pMeanError(p=4))\n",
    "\n",
    "@tf.function\n",
    "def axioms(features,label_protocol_type,label_flag):\n",
    "    x = ltn.Variable(\"x\",features)\n",
    "    x_tcp = ltn.Variable(\"x_tcp\",features[label_protocol_type==\"TCP\"])\n",
    "    x_icmp = ltn.Variable(\"x_icmp\",features[label_protocol_type==\"ICMP\"])\n",
    "    x_udp = ltn.Variable(\"x_udp\",features[label_protocol_type==\"UDP\"])\n",
    "    # x_sf = ltn.Variable(\"x_sf\",features[label_flag==\"SF\"])\n",
    "    # x_s1 = ltn.Variable(\"x_s1\",features[label_flag==\"S1\"])\n",
    "    # x_rej = ltn.Variable(\"x_rej\",features[label_flag==\"REJ\"])\n",
    "    # x_s2 = ltn.Variable(\"x_s2\",features[label_flag==\"S2\"])\n",
    "    # x_s0 = ltn.Variable(\"x_s0\",features[label_flag==\"S0\"])\n",
    "    # x_s3 = ltn.Variable(\"x_s3\",features[label_flag==\"S3\"])\n",
    "    # x_rsto = ltn.Variable(\"x_rsto\",features[label_flag==\"RSTO\"])\n",
    "    # x_rstr = ltn.Variable(\"x_rstr\",features[label_flag==\"RSTR\"])\n",
    "    # x_rstos0 = ltn.Variable(\"x_rstos0\",features[label_flag==\"RSTOS0\"])\n",
    "    # x_oth = ltn.Variable(\"x_oth\",features[label_flag==\"OTH\"])\n",
    "    # x_sh = ltn.Variable(\"x_sh\",features[label_flag==\"SH\"])\n",
    "    axioms = [\n",
    "        Forall(x_tcp, p([x_tcp,class_tcp])),\n",
    "        Forall(x_udp, p([x_udp,class_udp])),\n",
    "        Forall(x_icmp, p([x_icmp,class_icmp])),\n",
    "        # Forall(x_sf, p([x_sf,class_sf])),\n",
    "        # Forall(x_s1, p([x_s1,class_s1])),\n",
    "        # Forall(x_rej, p([x_rej,class_rej])),\n",
    "        # Forall(x_s2, p([x_s2,class_s2])),\n",
    "        # Forall(x_s0, p([x_s0,class_s0])),\n",
    "        # Forall(x_s3, p([x_s3,class_s3])),\n",
    "        # Forall(x_rsto, p([x_rsto,class_rsto])),\n",
    "        # Forall(x_rstr, p([x_rstr,class_rstr])),\n",
    "        # Forall(x_rstos0, p([x_rstos0,class_rstos0])),\n",
    "        # Forall(x_oth, p([x_oth,class_oth])),\n",
    "        # Forall(x_sh, p([x_sh,class_sh])),\n",
    "        \n",
    "        Forall(x,Not(And(p([x,class_tcp]),p([x,class_udp])))),\n",
    "        Forall(x,Not(And(p([x,class_icmp]),p([x,class_udp])))),\n",
    "        Forall(x,Not(And(p([x,class_tcp]),p([x,class_icmp])))),\n",
    "        \n",
    "        #Forall(x,Not(And(p([x,class_sf]),p([x,class_s1])))),\n",
    "        # Forall(x,Not(And(p([x,class_sf]),p([x,class_rej])))),\n",
    "        # Forall(x,Not(And(p([x,class_sf]),p([x,class_s2])))),\n",
    "        # Forall(x,Not(And(p([x,class_sf]),p([x,class_s0])))),\n",
    "        # Forall(x,Not(And(p([x,class_sf]),p([x,class_s3])))),\n",
    "        # Forall(x,Not(And(p([x,class_sf]),p([x,class_rsto])))),\n",
    "        # Forall(x,Not(And(p([x,class_sf]),p([x,class_rstr])))),\n",
    "        # Forall(x,Not(And(p([x,class_sf]),p([x,class_rstos0])))),\n",
    "        # Forall(x,Not(And(p([x,class_sf]),p([x,class_oth])))),\n",
    "        # Forall(x,Not(And(p([x,class_sf]),p([x,class_sh])))),\n",
    "        \n",
    "        # Forall(x,Not(And(p([x,class_s1]),p([x,class_rej])))),\n",
    "        # Forall(x,Not(And(p([x,class_s1]),p([x,class_s2])))),\n",
    "        # Forall(x,Not(And(p([x,class_s1]),p([x,class_s0])))),\n",
    "        # Forall(x,Not(And(p([x,class_s1]),p([x,class_s3])))),\n",
    "        # Forall(x,Not(And(p([x,class_s1]),p([x,class_rsto])))),\n",
    "        # Forall(x,Not(And(p([x,class_s1]),p([x,class_rstr])))),\n",
    "        # Forall(x,Not(And(p([x,class_s1]),p([x,class_rstos0])))),\n",
    "        # Forall(x,Not(And(p([x,class_s1]),p([x,class_oth])))),\n",
    "        # Forall(x,Not(And(p([x,class_s1]),p([x,class_sh])))),\n",
    "        \n",
    "#         Forall(x,Not(And(p([x,class_rej]),p([x,class_s2])))),\n",
    "#         Forall(x,Not(And(p([x,class_rej]),p([x,class_s0])))),\n",
    "#         Forall(x,Not(And(p([x,class_rej]),p([x,class_s3])))),\n",
    "#         Forall(x,Not(And(p([x,class_rej]),p([x,class_rsto])))),\n",
    "#         Forall(x,Not(And(p([x,class_rej]),p([x,class_rstr])))),\n",
    "#         Forall(x,Not(And(p([x,class_rej]),p([x,class_rstos0])))),\n",
    "#         Forall(x,Not(And(p([x,class_rej]),p([x,class_oth])))),\n",
    "#         Forall(x,Not(And(p([x,class_rej]),p([x,class_sh])))),\n",
    "        \n",
    "#         Forall(x,Not(And(p([x,class_s2]),p([x,class_s0])))),\n",
    "#         Forall(x,Not(And(p([x,class_s2]),p([x,class_s3])))),\n",
    "#         Forall(x,Not(And(p([x,class_s2]),p([x,class_rsto])))),\n",
    "#         Forall(x,Not(And(p([x,class_s2]),p([x,class_rstr])))),\n",
    "#         Forall(x,Not(And(p([x,class_s2]),p([x,class_rstos0])))),\n",
    "#         Forall(x,Not(And(p([x,class_s2]),p([x,class_oth])))),\n",
    "#         Forall(x,Not(And(p([x,class_s2]),p([x,class_sh])))),\n",
    "        \n",
    "#         Forall(x,Not(And(p([x,class_s0]),p([x,class_s3])))),\n",
    "#         Forall(x,Not(And(p([x,class_s0]),p([x,class_rsto])))),\n",
    "#         Forall(x,Not(And(p([x,class_s0]),p([x,class_rstr])))),\n",
    "#         Forall(x,Not(And(p([x,class_s0]),p([x,class_rstos0])))),\n",
    "#         Forall(x,Not(And(p([x,class_s0]),p([x,class_oth])))),\n",
    "#         Forall(x,Not(And(p([x,class_s0]),p([x,class_sh])))),\n",
    "        \n",
    "#         Forall(x,Not(And(p([x,class_s3]),p([x,class_rsto])))),\n",
    "#         Forall(x,Not(And(p([x,class_s3]),p([x,class_rstr])))),\n",
    "#         Forall(x,Not(And(p([x,class_s3]),p([x,class_rstos0])))),\n",
    "#         Forall(x,Not(And(p([x,class_s3]),p([x,class_oth])))),\n",
    "#         Forall(x,Not(And(p([x,class_s3]),p([x,class_sh])))),\n",
    "        \n",
    "#         Forall(x,Not(And(p([x,class_rsto]),p([x,class_rstr])))),\n",
    "#         Forall(x,Not(And(p([x,class_rsto]),p([x,class_rstos0])))),\n",
    "#         Forall(x,Not(And(p([x,class_rsto]),p([x,class_oth])))),\n",
    "#         Forall(x,Not(And(p([x,class_rsto]),p([x,class_sh])))),\n",
    "        \n",
    "#         Forall(x,Not(And(p([x,class_rstr]),p([x,class_rstos0])))),\n",
    "#         Forall(x,Not(And(p([x,class_rstr]),p([x,class_oth])))),\n",
    "#         Forall(x,Not(And(p([x,class_rstr]),p([x,class_sh])))),\n",
    "        \n",
    "#         Forall(x,Not(And(p([x,class_rstos0]),p([x,class_oth])))),\n",
    "#         Forall(x,Not(And(p([x,class_rstos0]),p([x,class_sh])))),\n",
    "        \n",
    "#         Forall(x,Not(And(p([x,class_oth]),p([x,class_sh])))),\n",
    "    ]\n",
    "    sat_level = formula_aggregator(axioms).tensor\n",
    "    return sat_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83aabb19-155c-4f10-8a58-f87747eb7978",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-03 22:11:21.286977: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-01-03 22:11:21.287855: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-03 22:11:21.595102: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at gather_nd_op.cc:47 : INVALID_ARGUMENT: indices[63,0] = [63, 2] does not index into param shape [64,2], node name: logits_to_predicate_model/BatchGatherND_4/GatherNd\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "2 root error(s) found.\n  (0) INVALID_ARGUMENT:  indices[63,0] = [63, 2] does not index into param shape [64,2], node name: logits_to_predicate_model/BatchGatherND_4/GatherNd\n\t [[node logits_to_predicate_model/BatchGatherND_4/GatherNd\n (defined at /Users/eduard.hogea/Documents/Facultate/Internship/logictensornetworks-master/logictensornetworks/utils.py:68)\n]]\n\t [[logits_to_predicate_model/BatchGatherND_4/GatherNd/_222]]\n  (1) INVALID_ARGUMENT:  indices[63,0] = [63, 2] does not index into param shape [64,2], node name: logits_to_predicate_model/BatchGatherND_4/GatherNd\n\t [[node logits_to_predicate_model/BatchGatherND_4/GatherNd\n (defined at /Users/eduard.hogea/Documents/Facultate/Internship/logictensornetworks-master/logictensornetworks/utils.py:68)\n]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_axioms_3405]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node logits_to_predicate_model/BatchGatherND_4/GatherNd:\nIn[0] logits_to_predicate_model/Sigmoid_4 (defined at /Users/eduard.hogea/Documents/Facultate/Internship/logictensornetworks-master/logictensornetworks/utils.py:65)\t\nIn[1] logits_to_predicate_model/BatchGatherND_4/concat_3:\n\nOperation defined at: (most recent call last)\n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/asyncio/events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"/var/folders/9m/k3vyv4317cz56g6f681k4jnm0000gn/T/ipykernel_6500/3473804032.py\", line 2, in <module>\n>>>     print(\"Initial sat level %.5f\"%axioms(features,label_protocol_type,label_flag))\n>>> \n>>>   File \"/var/folders/9m/k3vyv4317cz56g6f681k4jnm0000gn/T/ipykernel_6500/1939805140.py\", line 20, in axioms\n>>>     axioms = [\n>>> \n>>>   File \"/Users/eduard.hogea/Documents/Facultate/Internship/logictensornetworks-master/logictensornetworks/core.py\", line 186, in __call__\n>>>     raise TypeError(\"The input to a LTN Predicate should be instances of %s. \"\\\n>>> \n>>>   File \"/Users/eduard.hogea/Documents/Facultate/Internship/logictensornetworks-master/logictensornetworks/core.py\", line 149, in __call__\n>>>     if not isinstance(inputs,(list,tuple)):\n>>> \n>>>   File \"/Users/eduard.hogea/Documents/Facultate/Internship/logictensornetworks-master/logictensornetworks/core.py\", line 156, in __call__\n>>>     t_outputs = self.model(as_tensors(flat_inputs), *args, **kwargs)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/Users/eduard.hogea/Documents/Facultate/Internship/logictensornetworks-master/logictensornetworks/utils.py\", line 68, in call\n>>>     return tf.gather_nd(probs, indices, batch_dims=1)\n>>> \n\nInput Source operations connected to node logits_to_predicate_model/BatchGatherND_4/GatherNd:\nIn[0] logits_to_predicate_model/Sigmoid_4 (defined at /Users/eduard.hogea/Documents/Facultate/Internship/logictensornetworks-master/logictensornetworks/utils.py:65)\t\nIn[1] logits_to_predicate_model/BatchGatherND_4/concat_3:\n\nOperation defined at: (most recent call last)\n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/asyncio/events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"/var/folders/9m/k3vyv4317cz56g6f681k4jnm0000gn/T/ipykernel_6500/3473804032.py\", line 2, in <module>\n>>>     print(\"Initial sat level %.5f\"%axioms(features,label_protocol_type,label_flag))\n>>> \n>>>   File \"/var/folders/9m/k3vyv4317cz56g6f681k4jnm0000gn/T/ipykernel_6500/1939805140.py\", line 20, in axioms\n>>>     axioms = [\n>>> \n>>>   File \"/Users/eduard.hogea/Documents/Facultate/Internship/logictensornetworks-master/logictensornetworks/core.py\", line 186, in __call__\n>>>     raise TypeError(\"The input to a LTN Predicate should be instances of %s. \"\\\n>>> \n>>>   File \"/Users/eduard.hogea/Documents/Facultate/Internship/logictensornetworks-master/logictensornetworks/core.py\", line 149, in __call__\n>>>     if not isinstance(inputs,(list,tuple)):\n>>> \n>>>   File \"/Users/eduard.hogea/Documents/Facultate/Internship/logictensornetworks-master/logictensornetworks/core.py\", line 156, in __call__\n>>>     t_outputs = self.model(as_tensors(flat_inputs), *args, **kwargs)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/Users/eduard.hogea/Documents/Facultate/Internship/logictensornetworks-master/logictensornetworks/utils.py\", line 68, in call\n>>>     return tf.gather_nd(probs, indices, batch_dims=1)\n>>> \n\nFunction call stack:\naxioms -> axioms\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9m/k3vyv4317cz56g6f681k4jnm0000gn/T/ipykernel_6500/3473804032.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_protocol_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_flag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mds_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initial sat level %.5f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0maxioms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_protocol_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_flag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) INVALID_ARGUMENT:  indices[63,0] = [63, 2] does not index into param shape [64,2], node name: logits_to_predicate_model/BatchGatherND_4/GatherNd\n\t [[node logits_to_predicate_model/BatchGatherND_4/GatherNd\n (defined at /Users/eduard.hogea/Documents/Facultate/Internship/logictensornetworks-master/logictensornetworks/utils.py:68)\n]]\n\t [[logits_to_predicate_model/BatchGatherND_4/GatherNd/_222]]\n  (1) INVALID_ARGUMENT:  indices[63,0] = [63, 2] does not index into param shape [64,2], node name: logits_to_predicate_model/BatchGatherND_4/GatherNd\n\t [[node logits_to_predicate_model/BatchGatherND_4/GatherNd\n (defined at /Users/eduard.hogea/Documents/Facultate/Internship/logictensornetworks-master/logictensornetworks/utils.py:68)\n]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_axioms_3405]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node logits_to_predicate_model/BatchGatherND_4/GatherNd:\nIn[0] logits_to_predicate_model/Sigmoid_4 (defined at /Users/eduard.hogea/Documents/Facultate/Internship/logictensornetworks-master/logictensornetworks/utils.py:65)\t\nIn[1] logits_to_predicate_model/BatchGatherND_4/concat_3:\n\nOperation defined at: (most recent call last)\n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/asyncio/events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"/var/folders/9m/k3vyv4317cz56g6f681k4jnm0000gn/T/ipykernel_6500/3473804032.py\", line 2, in <module>\n>>>     print(\"Initial sat level %.5f\"%axioms(features,label_protocol_type,label_flag))\n>>> \n>>>   File \"/var/folders/9m/k3vyv4317cz56g6f681k4jnm0000gn/T/ipykernel_6500/1939805140.py\", line 20, in axioms\n>>>     axioms = [\n>>> \n>>>   File \"/Users/eduard.hogea/Documents/Facultate/Internship/logictensornetworks-master/logictensornetworks/core.py\", line 186, in __call__\n>>>     raise TypeError(\"The input to a LTN Predicate should be instances of %s. \"\\\n>>> \n>>>   File \"/Users/eduard.hogea/Documents/Facultate/Internship/logictensornetworks-master/logictensornetworks/core.py\", line 149, in __call__\n>>>     if not isinstance(inputs,(list,tuple)):\n>>> \n>>>   File \"/Users/eduard.hogea/Documents/Facultate/Internship/logictensornetworks-master/logictensornetworks/core.py\", line 156, in __call__\n>>>     t_outputs = self.model(as_tensors(flat_inputs), *args, **kwargs)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/Users/eduard.hogea/Documents/Facultate/Internship/logictensornetworks-master/logictensornetworks/utils.py\", line 68, in call\n>>>     return tf.gather_nd(probs, indices, batch_dims=1)\n>>> \n\nInput Source operations connected to node logits_to_predicate_model/BatchGatherND_4/GatherNd:\nIn[0] logits_to_predicate_model/Sigmoid_4 (defined at /Users/eduard.hogea/Documents/Facultate/Internship/logictensornetworks-master/logictensornetworks/utils.py:65)\t\nIn[1] logits_to_predicate_model/BatchGatherND_4/concat_3:\n\nOperation defined at: (most recent call last)\n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/asyncio/events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"/var/folders/9m/k3vyv4317cz56g6f681k4jnm0000gn/T/ipykernel_6500/3473804032.py\", line 2, in <module>\n>>>     print(\"Initial sat level %.5f\"%axioms(features,label_protocol_type,label_flag))\n>>> \n>>>   File \"/var/folders/9m/k3vyv4317cz56g6f681k4jnm0000gn/T/ipykernel_6500/1939805140.py\", line 20, in axioms\n>>>     axioms = [\n>>> \n>>>   File \"/Users/eduard.hogea/Documents/Facultate/Internship/logictensornetworks-master/logictensornetworks/core.py\", line 186, in __call__\n>>>     raise TypeError(\"The input to a LTN Predicate should be instances of %s. \"\\\n>>> \n>>>   File \"/Users/eduard.hogea/Documents/Facultate/Internship/logictensornetworks-master/logictensornetworks/core.py\", line 149, in __call__\n>>>     if not isinstance(inputs,(list,tuple)):\n>>> \n>>>   File \"/Users/eduard.hogea/Documents/Facultate/Internship/logictensornetworks-master/logictensornetworks/core.py\", line 156, in __call__\n>>>     t_outputs = self.model(as_tensors(flat_inputs), *args, **kwargs)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/Users/eduard.hogea/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/Users/eduard.hogea/Documents/Facultate/Internship/logictensornetworks-master/logictensornetworks/utils.py\", line 68, in call\n>>>     return tf.gather_nd(probs, indices, batch_dims=1)\n>>> \n\nFunction call stack:\naxioms -> axioms\n"
     ]
    }
   ],
   "source": [
    "for features, label_protocol_type, label_flag in ds_train:\n",
    "    print(\"Initial sat level %.5f\"%axioms(features,label_protocol_type,label_flag))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cdd35a-fe99-4d93-bf0d-9dace145880a",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f3618d-ddea-433f-a6a6-5875a55d8ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = {\n",
    "    'train_sat_kb': tf.keras.metrics.Mean(name='train_sat_kb'),\n",
    "    'test_sat_kb': tf.keras.metrics.Mean(name='test_sat_kb'),\n",
    "    'train_accuracy': tf.keras.metrics.Mean(name=\"train_accuracy\"),\n",
    "    'test_accuracy': tf.keras.metrics.Mean(name=\"test_accuracy\"),\n",
    "    'test_sat_phi1': tf.keras.metrics.Mean(name='test_sat_phi1'),\n",
    "    'test_sat_phi2': tf.keras.metrics.Mean(name='test_sat_phi2'),\n",
    "    'test_sat_phi3': tf.keras.metrics.Mean(name='test_sat_phi3')\n",
    "}\n",
    "\n",
    "@tf.function()\n",
    "def sat_phi1(features):\n",
    "    x = ltn.Variable(\"x\",features)\n",
    "    phi1 = Forall(x, Implies(p([x,class_udp]),Not(p([x,class_tcp]))),p=5)\n",
    "    return phi1.tensor\n",
    "\n",
    "@tf.function()\n",
    "def sat_phi2(features):\n",
    "    x = ltn.Variable(\"x\",features)\n",
    "    phi2 = Forall(x, Implies(p([x,class_udp]),p([x,class_tcp])),p=5)\n",
    "    return phi2.tensor\n",
    "\n",
    "@tf.function()\n",
    "def sat_phi3(features):\n",
    "    x = ltn.Variable(\"x\",features)\n",
    "    phi3 = Forall(x, Implies(p([x,class_tcp]),p([x,class_icmp])),p=5)\n",
    "    return phi3.tensor\n",
    "\n",
    "def multilabel_hamming_loss(y_true, y_pred, threshold=0.5,from_logits=False):\n",
    "    if from_logits:\n",
    "        y_pred = tf.math.sigmoid(y_pred)\n",
    "    y_pred = y_pred > threshold\n",
    "    y_true = tf.cast(y_true, tf.int32)\n",
    "    y_pred = tf.cast(y_pred, tf.int32)\n",
    "    nonzero = tf.cast(tf.math.count_nonzero(y_true-y_pred,axis=-1),tf.float32)\n",
    "    return nonzero/y_true.get_shape()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29091238-591b-45fd-954c-33252dfb1381",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "@tf.function\n",
    "def train_step(features, label_protocol_type, label_flag):\n",
    "    # sat and update\n",
    "    with tf.GradientTape() as tape:\n",
    "        sat = axioms(features, label_protocol_type, label_flag)\n",
    "        loss = 1.-sat\n",
    "    gradients = tape.gradient(loss, p.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, p.trainable_variables))\n",
    "    metrics_dict['train_sat_kb'](sat)\n",
    "    # accuracy\n",
    "    predictions = logits_model(features)\n",
    "    label_tcp = (label_protocol_type == \"TCP\")\n",
    "    label_icmp = (label_protocol_type == \"ICMP\")\n",
    "    label_udp = (label_protocol_type == \"UDP\")\n",
    "    # label_sf = (label_flag == \"SF\")\n",
    "    # label_s1 = (label_flag == \"S1\")\n",
    "    # label_rej = (label_flag == \"REJ\")\n",
    "    # label_s2 = (label_flag == \"S2\")\n",
    "    # label_s0 = (label_flag == \"S0\")\n",
    "    # label_s3 = (label_flag == \"S3\")\n",
    "    # label_rsto = (label_flag == \"RSTO\")\n",
    "    # label_rstr = (label_flag == \"RSTR\")\n",
    "    # label_rstos0 = (label_flag == \"RSTOS0\")\n",
    "    # label_oth = (label_flag == \"OTH\")\n",
    "    # label_sh = (label_flag == \"SH\")\n",
    "    \n",
    "\n",
    "    #onehot = tf.stack([label_tcp,label_icmp,label_udp,label_sf,label_s1,label_rej,label_s2,label_s0,label_s3,label_rsto,label_rstr,label_rstos0,label_oth,label_sh],axis=-1)\n",
    "    onehot = tf.stack([label_tcp,label_icmp,label_udp],axis=-1)\n",
    "    metrics_dict['train_accuracy'](1-multilabel_hamming_loss(onehot,predictions,from_logits=True))\n",
    "    \n",
    "@tf.function\n",
    "def test_step(features, label_protocol_type, label_flag):\n",
    "    # sat\n",
    "    sat_kb = axioms(features, label_protocol_type, label_flag)\n",
    "    metrics_dict['test_sat_kb'](sat_kb)\n",
    "    metrics_dict['test_sat_phi1'](sat_phi1(features))\n",
    "    metrics_dict['test_sat_phi2'](sat_phi2(features))\n",
    "    metrics_dict['test_sat_phi3'](sat_phi3(features))\n",
    "    # accuracy\n",
    "    predictions = logits_model(features)\n",
    "    label_tcp = (label_protocol_type == \"TCP\")\n",
    "    label_icmp = (label_protocol_type == \"ICMP\")\n",
    "    label_udp = (label_protocol_type == \"UDP\")\n",
    "    #label_sf = (label_flag == \"SF\")\n",
    "    # label_s1 = (label_flag == \"S1\")\n",
    "    # label_rej = (label_flag == \"REJ\")\n",
    "    # label_s2 = (label_flag == \"S2\")\n",
    "    # label_s0 = (label_flag == \"S0\")\n",
    "    # label_s3 = (label_flag == \"S3\")\n",
    "    # label_rsto = (label_flag == \"RSTO\")\n",
    "    # label_rstr = (label_flag == \"RSTR\")\n",
    "    # label_rstos0 = (label_flag == \"RSTOS0\")\n",
    "    # label_oth = (label_flag == \"OTH\")\n",
    "    # label_sh = (label_flag == \"SH\")\n",
    "    #onehot = tf.stack([label_tcp,label_icmp,label_udp,label_sf,label_s1,label_rej,label_s2,label_s0,label_s3,label_rsto,label_rstr,label_rstos0,label_oth,label_sh],axis=-1)\n",
    "    onehot = tf.stack([label_tcp,label_icmp,label_udp],axis=-1)\n",
    "    metrics_dict['test_accuracy'](1-multilabel_hamming_loss(onehot,predictions,from_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8861a1-1a0e-4e9d-b4eb-5447da40c483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def train(\n",
    "        epochs,\n",
    "        metrics_dict, \n",
    "        ds_train, \n",
    "        ds_test, \n",
    "        train_step, \n",
    "        test_step,\n",
    "        track_metrics=1,\n",
    "        csv_path=None,\n",
    "        scheduled_parameters=defaultdict(lambda : {})\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        epochs: int, number of training epochs.\n",
    "        metrics_dict: dict, {\"metrics_label\": tf.keras.metrics instance}.\n",
    "        ds_train: iterable dataset, e.g. using tf.data.Dataset.\n",
    "        ds_test: iterable dataset, e.g. using tf.data.Dataset.\n",
    "        train_step: callable function. the arguments passed to the function\n",
    "            are the itered elements of ds_train.\n",
    "        test_step: callable function. the arguments passed to the function\n",
    "            are the itered elements of ds_test.\n",
    "        csv_path: (optional) path to create a csv file, to save the metrics.\n",
    "        scheduled_parameters: (optional) a dictionary that returns kwargs for\n",
    "            the train_step and test_step functions, for each epoch.\n",
    "            Call using scheduled_parameters[epoch].\n",
    "    \"\"\"\n",
    "    template = \"Epoch {}\"\n",
    "    for metrics_label in metrics_dict.keys():\n",
    "        template += \", %s: {:.4f}\" % metrics_label\n",
    "    if csv_path is not None:\n",
    "        csv_file = open(csv_path,\"w+\")\n",
    "        headers = \",\".join([\"Epoch\"]+list(metrics_dict.keys()))\n",
    "        csv_template = \",\".join([\"{}\" for _ in range(len(metrics_dict)+1)])\n",
    "        csv_file.write(headers+\"\\n\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for metrics in metrics_dict.values():\n",
    "            metrics.reset_states()\n",
    "\n",
    "        for batch_elements in ds_train:\n",
    "            train_step(*batch_elements,**scheduled_parameters[epoch])\n",
    "        for batch_elements in ds_test:\n",
    "            test_step(*batch_elements,**scheduled_parameters[epoch])\n",
    "\n",
    "        metrics_results = [metrics.result() for metrics in metrics_dict.values()]\n",
    "        if epoch%track_metrics == 0:\n",
    "            print(template.format(epoch,*metrics_results))\n",
    "        if csv_path is not None:\n",
    "            csv_file.write(csv_template.format(epoch,*metrics_results)+\"\\n\")\n",
    "            csv_file.flush()\n",
    "    if csv_path is not None:\n",
    "        csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5172a5-8eeb-40a9-831a-763e46d3cd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "train(\n",
    "    EPOCHS,\n",
    "    metrics_dict,\n",
    "    ds_train,\n",
    "    ds_test,\n",
    "    train_step,\n",
    "    test_step,\n",
    "    csv_path=\"results.csv\",\n",
    "    track_metrics=20\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
