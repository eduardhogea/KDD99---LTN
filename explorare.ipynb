{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5c5ec92-5dbe-45ea-b575-800568605af3",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34c5925e-32be-4108-afd3-57d144b3fa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logictensornetworks as ltn\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250efae2-5a1c-4922-9a1d-cfa6a0f98bff",
   "metadata": {},
   "source": [
    "# Dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cc32e28-2707-4bd0-ac2a-118486a818db",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "df = pd.read_csv(\"kddcup99.csv\", skipinitialspace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "286f1102-1443-453e-af3b-df7cd19601c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(494020, 42)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape #numar de linii si coloane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23066d9d-7d8d-4c86-8705-2d8b05a13e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145585, 42)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(keep= 'first', inplace=True) #eliminarea dublurilor liniilor\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a72b1a2b-d288-4e10-8b23-4d8c94f32d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>lnum_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>145585.000000</td>\n",
       "      <td>1.455850e+05</td>\n",
       "      <td>1.455850e+05</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "      <td>145585.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>132.026088</td>\n",
       "      <td>7.995752e+03</td>\n",
       "      <td>2.859788e+03</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.020201</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.100175</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.491486</td>\n",
       "      <td>0.026177</td>\n",
       "      <td>...</td>\n",
       "      <td>181.469423</td>\n",
       "      <td>129.935570</td>\n",
       "      <td>0.553226</td>\n",
       "      <td>0.061389</td>\n",
       "      <td>0.092826</td>\n",
       "      <td>0.019048</td>\n",
       "      <td>0.291599</td>\n",
       "      <td>0.290980</td>\n",
       "      <td>0.110464</td>\n",
       "      <td>0.107676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1224.161209</td>\n",
       "      <td>1.820390e+06</td>\n",
       "      <td>6.081000e+04</td>\n",
       "      <td>0.011720</td>\n",
       "      <td>0.239369</td>\n",
       "      <td>0.010150</td>\n",
       "      <td>1.426803</td>\n",
       "      <td>0.028586</td>\n",
       "      <td>0.499929</td>\n",
       "      <td>3.311384</td>\n",
       "      <td>...</td>\n",
       "      <td>99.097396</td>\n",
       "      <td>114.714717</td>\n",
       "      <td>0.456236</td>\n",
       "      <td>0.147021</td>\n",
       "      <td>0.241124</td>\n",
       "      <td>0.060410</td>\n",
       "      <td>0.452493</td>\n",
       "      <td>0.453448</td>\n",
       "      <td>0.306098</td>\n",
       "      <td>0.304221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.470000e+02</td>\n",
       "      <td>1.050000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.880000e+02</td>\n",
       "      <td>1.164000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>58329.000000</td>\n",
       "      <td>6.933756e+08</td>\n",
       "      <td>5.155468e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>884.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            duration     src_bytes     dst_bytes           land  \\\n",
       "count  145585.000000  1.455850e+05  1.455850e+05  145585.000000   \n",
       "mean      132.026088  7.995752e+03  2.859788e+03       0.000137   \n",
       "std      1224.161209  1.820390e+06  6.081000e+04       0.011720   \n",
       "min         0.000000  0.000000e+00  0.000000e+00       0.000000   \n",
       "25%         0.000000  0.000000e+00  0.000000e+00       0.000000   \n",
       "50%         0.000000  1.470000e+02  1.050000e+02       0.000000   \n",
       "75%         0.000000  2.880000e+02  1.164000e+03       0.000000   \n",
       "max     58329.000000  6.933756e+08  5.155468e+06       1.000000   \n",
       "\n",
       "       wrong_fragment         urgent            hot  num_failed_logins  \\\n",
       "count   145585.000000  145585.000000  145585.000000      145585.000000   \n",
       "mean         0.020201       0.000048       0.100175           0.000515   \n",
       "std          0.239369       0.010150       1.426803           0.028586   \n",
       "min          0.000000       0.000000       0.000000           0.000000   \n",
       "25%          0.000000       0.000000       0.000000           0.000000   \n",
       "50%          0.000000       0.000000       0.000000           0.000000   \n",
       "75%          0.000000       0.000000       0.000000           0.000000   \n",
       "max          3.000000       3.000000      30.000000           5.000000   \n",
       "\n",
       "           logged_in  lnum_compromised  ...  dst_host_count  \\\n",
       "count  145585.000000     145585.000000  ...   145585.000000   \n",
       "mean        0.491486          0.026177  ...      181.469423   \n",
       "std         0.499929          3.311384  ...       99.097396   \n",
       "min         0.000000          0.000000  ...        0.000000   \n",
       "25%         0.000000          0.000000  ...       78.000000   \n",
       "50%         0.000000          0.000000  ...      255.000000   \n",
       "75%         1.000000          0.000000  ...      255.000000   \n",
       "max         1.000000        884.000000  ...      255.000000   \n",
       "\n",
       "       dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "count       145585.000000           145585.000000           145585.000000   \n",
       "mean           129.935570                0.553226                0.061389   \n",
       "std            114.714717                0.456236                0.147021   \n",
       "min              0.000000                0.000000                0.000000   \n",
       "25%             12.000000                0.050000                0.000000   \n",
       "50%            117.000000                0.770000                0.020000   \n",
       "75%            255.000000                1.000000                0.070000   \n",
       "max            255.000000                1.000000                1.000000   \n",
       "\n",
       "       dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "count                145585.000000                145585.000000   \n",
       "mean                      0.092826                     0.019048   \n",
       "std                       0.241124                     0.060410   \n",
       "min                       0.000000                     0.000000   \n",
       "25%                       0.000000                     0.000000   \n",
       "50%                       0.000000                     0.000000   \n",
       "75%                       0.030000                     0.020000   \n",
       "max                       1.000000                     1.000000   \n",
       "\n",
       "       dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "count         145585.000000             145585.000000         145585.000000   \n",
       "mean               0.291599                  0.290980              0.110464   \n",
       "std                0.452493                  0.453448              0.306098   \n",
       "min                0.000000                  0.000000              0.000000   \n",
       "25%                0.000000                  0.000000              0.000000   \n",
       "50%                0.000000                  0.000000              0.000000   \n",
       "75%                1.000000                  1.000000              0.000000   \n",
       "max                1.000000                  1.000000              1.000000   \n",
       "\n",
       "       dst_host_srv_rerror_rate  \n",
       "count             145585.000000  \n",
       "mean                   0.107676  \n",
       "std                    0.304221  \n",
       "min                    0.000000  \n",
       "25%                    0.000000  \n",
       "50%                    0.000000  \n",
       "75%                    0.000000  \n",
       "max                    1.000000  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd85ce89-c5e4-40fb-b382-020e4e2f2bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1) #shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b1d0dbb-1008-4ff6-9ad0-b79a1efbbba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 21:40:04.416806: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-01-25 21:40:04.416897: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "features = df[['duration', 'src_bytes','dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot','num_failed_logins', 'logged_in', 'lnum_compromised', 'lroot_shell','lsu_attempted', 'lnum_root', 'lnum_file_creations', 'lnum_shells','lnum_access_files', 'lnum_outbound_cmds', 'is_host_login','is_guest_login', 'count', 'srv_count', 'serror_rate','srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate','diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count','dst_host_srv_count', 'dst_host_same_srv_rate','dst_host_diff_srv_rate', 'dst_host_same_src_port_rate','dst_host_srv_diff_host_rate', 'dst_host_serror_rate','dst_host_srv_serror_rate', 'dst_host_rerror_rate','dst_host_srv_rerror_rate']]\n",
    "label_protocol_type = df['protocol_type']\n",
    "label_flag = df['flag']\n",
    "batch_size=64\n",
    "\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((features[:120000],label_protocol_type[:120000],label_flag[:120000])).batch(batch_size)\n",
    "ds_test = tf.data.Dataset.from_tensor_slices((features[120000:],label_protocol_type[120000:],label_flag[120000:])).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26397801-33a9-4e3f-8de1-8bb2ef66820f",
   "metadata": {},
   "source": [
    "# Creare model\n",
    "\n",
    "### Predicate\n",
    "\n",
    "| index | class | \n",
    "| --- | --- |\n",
    "| 0 | TCP |\n",
    "| 1 | ICMP |\n",
    "| 2 | UDP |\n",
    "| 3 | SF |\n",
    "| 4 | S1 |\n",
    "| 5 | REJ |\n",
    "| 6 | S2 |\n",
    "| 7 | S0 |\n",
    "| 8 | S3 |\n",
    "| 9 | RSTO |\n",
    "| 10 | RSTR |\n",
    "| 11 | RSTOS0 |\n",
    "| 12 | OTH |\n",
    "| 13 | SH |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f15619b-ec0c-4938-861a-b44965aee1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.Model):\n",
    "    \"\"\"Model that returns logits.\"\"\"\n",
    "    def __init__(self, n_classes, hidden_layer_sizes=(16,16,8)):\n",
    "        super(MLP, self).__init__()\n",
    "        self.denses = [tf.keras.layers.Dense(s, activation=\"elu\") for s in hidden_layer_sizes]\n",
    "        self.dense_class = tf.keras.layers.Dense(n_classes)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        for dense in self.denses:\n",
    "            x = dense(x)\n",
    "        return self.dense_class(x)\n",
    "\n",
    "logits_model = MLP(14)\n",
    "p = ltn.Predicate(ltn.utils.LogitsToPredicateModel(logits_model,single_label=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9175e09d-b2dc-480d-95e0-121d9d58c356",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_tcp = ltn.Constant(0, trainable=False)\n",
    "class_icmp = ltn.Constant(1, trainable=False)\n",
    "class_udp = ltn.Constant(2, trainable=False)\n",
    "class_sf = ltn.Constant(3, trainable=False)\n",
    "class_s1 = ltn.Constant(4, trainable=False)\n",
    "class_rej = ltn.Constant(5, trainable=False)\n",
    "class_s2 = ltn.Constant(6, trainable=False)\n",
    "class_s0 = ltn.Constant(7, trainable=False)\n",
    "class_s3 = ltn.Constant(8, trainable=False)\n",
    "class_rsto = ltn.Constant(9, trainable=False)\n",
    "class_rstr = ltn.Constant(10, trainable=False)\n",
    "class_rstos0 = ltn.Constant(11, trainable=False)\n",
    "class_oth = ltn.Constant(12, trainable=False)\n",
    "class_sh = ltn.Constant(13, trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c179e7a-0658-4a62-9464-796aaad860d6",
   "metadata": {},
   "source": [
    "# Logica si axiomele\n",
    "```\n",
    "forall x_tcp: C(x_tcp,tcp)\n",
    "forall x_icmp: C(x_icmp,icmp)\n",
    "forall x_udp: C(x_udp,udp)\n",
    "forall x_sf: C(x_sf,sf)\n",
    "forall x_s1: C(x_s1,s1)\n",
    "forall x_rej: C(x_rej,rej)\n",
    "forall x: ~(C(x,tcp) & C(x,sf))\n",
    "forall x: ~(C(x,icmp) & C(x,s1))\n",
    "forall x: ~(C(x,udp) & C(x,rej))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73fd4aa8-a4ef-4cfe-83be-fa54765500ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Not = ltn.Wrapper_Connective(ltn.fuzzy_ops.Not_Std())\n",
    "And = ltn.Wrapper_Connective(ltn.fuzzy_ops.And_Prod())\n",
    "Or = ltn.Wrapper_Connective(ltn.fuzzy_ops.Or_ProbSum())\n",
    "Implies = ltn.Wrapper_Connective(ltn.fuzzy_ops.Implies_Reichenbach())\n",
    "Equiv = ltn.Wrapper_Connective(ltn.fuzzy_ops.Equiv(ltn.fuzzy_ops.And_Prod(),ltn.fuzzy_ops.Implies_Reichenbach()))\n",
    "Forall = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMeanError(p=4),semantics=\"forall\")\n",
    "Exists = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMean(p=6),semantics=\"exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b774e1b8-9148-4769-ba51-495d19a86387",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_aggregator = ltn.Wrapper_Formula_Aggregator(ltn.fuzzy_ops.Aggreg_pMeanError(p=4))\n",
    "\n",
    "@tf.function\n",
    "def axioms(features,label_protocol_type,label_flag):\n",
    "    x = ltn.Variable(\"x\",features)\n",
    "    x_tcp = ltn.Variable(\"x_tcp\",features[label_protocol_type==\"TCP\"])\n",
    "    x_icmp = ltn.Variable(\"x_icmp\",features[label_protocol_type==\"ICMP\"])\n",
    "    x_udp = ltn.Variable(\"x_udp\",features[label_protocol_type==\"UDP\"])\n",
    "    x_sf = ltn.Variable(\"x_sf\",features[label_flag==\"SF\"])\n",
    "    x_s1 = ltn.Variable(\"x_s1\",features[label_flag==\"S1\"])\n",
    "    x_rej = ltn.Variable(\"x_rej\",features[label_flag==\"REJ\"])\n",
    "    x_s2 = ltn.Variable(\"x_s2\",features[label_flag==\"S2\"])\n",
    "    x_s0 = ltn.Variable(\"x_s0\",features[label_flag==\"S0\"])\n",
    "    x_s3 = ltn.Variable(\"x_s3\",features[label_flag==\"S3\"])\n",
    "    x_rsto = ltn.Variable(\"x_rsto\",features[label_flag==\"RSTO\"])\n",
    "    x_rstr = ltn.Variable(\"x_rstr\",features[label_flag==\"RSTR\"])\n",
    "    x_rstos0 = ltn.Variable(\"x_rstos0\",features[label_flag==\"RSTOS0\"])\n",
    "    x_oth = ltn.Variable(\"x_oth\",features[label_flag==\"OTH\"])\n",
    "    x_sh = ltn.Variable(\"x_sh\",features[label_flag==\"SH\"])\n",
    "    axioms = [\n",
    "        Forall(x_tcp, p([x_tcp,class_tcp])),\n",
    "        Forall(x_udp, p([x_udp,class_udp])),\n",
    "        Forall(x_icmp, p([x_icmp,class_icmp])),\n",
    "        Forall(x_sf, p([x_sf,class_sf])),\n",
    "        Forall(x_s1, p([x_s1,class_s1])),\n",
    "        Forall(x_rej, p([x_rej,class_rej])),\n",
    "        # Forall(x_s2, p([x_s2,class_s2])),\n",
    "        # Forall(x_s0, p([x_s0,class_s0])),\n",
    "        # Forall(x_s3, p([x_s3,class_s3])),\n",
    "        # Forall(x_rsto, p([x_rsto,class_rsto])),\n",
    "        # Forall(x_rstr, p([x_rstr,class_rstr])),\n",
    "        # Forall(x_rstos0, p([x_rstos0,class_rstos0])),\n",
    "        # Forall(x_oth, p([x_oth,class_oth])),\n",
    "        # Forall(x_sh, p([x_sh,class_sh])),\n",
    "        \n",
    "        Forall(x,Not(And(p([x,class_tcp]),p([x,class_sf])))),\n",
    "        Forall(x,Not(And(p([x,class_icmp]),p([x,class_s1])))),\n",
    "        Forall(x,Not(And(p([x,class_udp]),p([x,class_rej])))),\n",
    "        \n",
    "#         Forall(x,Not(And(p([x,class_sf]),p([x,class_s1])))),\n",
    "#         Forall(x,Not(And(p([x,class_sf]),p([x,class_rej])))),\n",
    "#         Forall(x,Not(And(p([x,class_sf]),p([x,class_s2])))),\n",
    "#         Forall(x,Not(And(p([x,class_sf]),p([x,class_s0])))),\n",
    "#         Forall(x,Not(And(p([x,class_sf]),p([x,class_s3])))),\n",
    "#         Forall(x,Not(And(p([x,class_sf]),p([x,class_rsto])))),\n",
    "#         Forall(x,Not(And(p([x,class_sf]),p([x,class_rstr])))),\n",
    "#         Forall(x,Not(And(p([x,class_sf]),p([x,class_rstos0])))),\n",
    "#         Forall(x,Not(And(p([x,class_sf]),p([x,class_oth])))),\n",
    "#         Forall(x,Not(And(p([x,class_sf]),p([x,class_sh])))),\n",
    "        \n",
    "#         Forall(x,Not(And(p([x,class_s1]),p([x,class_rej])))),\n",
    "#         Forall(x,Not(And(p([x,class_s1]),p([x,class_s2])))),\n",
    "#         Forall(x,Not(And(p([x,class_s1]),p([x,class_s0])))),\n",
    "#         Forall(x,Not(And(p([x,class_s1]),p([x,class_s3])))),\n",
    "#         Forall(x,Not(And(p([x,class_s1]),p([x,class_rsto])))),\n",
    "#         Forall(x,Not(And(p([x,class_s1]),p([x,class_rstr])))),\n",
    "#         Forall(x,Not(And(p([x,class_s1]),p([x,class_rstos0])))),\n",
    "#         Forall(x,Not(And(p([x,class_s1]),p([x,class_oth])))),\n",
    "#         Forall(x,Not(And(p([x,class_s1]),p([x,class_sh])))),\n",
    "        \n",
    "#         Forall(x,Not(And(p([x,class_rej]),p([x,class_s2])))),\n",
    "#         Forall(x,Not(And(p([x,class_rej]),p([x,class_s0])))),\n",
    "#         Forall(x,Not(And(p([x,class_rej]),p([x,class_s3])))),\n",
    "#         Forall(x,Not(And(p([x,class_rej]),p([x,class_rsto])))),\n",
    "#         Forall(x,Not(And(p([x,class_rej]),p([x,class_rstr])))),\n",
    "#         Forall(x,Not(And(p([x,class_rej]),p([x,class_rstos0])))),\n",
    "#         Forall(x,Not(And(p([x,class_rej]),p([x,class_oth])))),\n",
    "#         Forall(x,Not(And(p([x,class_rej]),p([x,class_sh])))),\n",
    "        \n",
    "#         Forall(x,Not(And(p([x,class_s2]),p([x,class_s0])))),\n",
    "#         Forall(x,Not(And(p([x,class_s2]),p([x,class_s3])))),\n",
    "#         Forall(x,Not(And(p([x,class_s2]),p([x,class_rsto])))),\n",
    "#         Forall(x,Not(And(p([x,class_s2]),p([x,class_rstr])))),\n",
    "#         Forall(x,Not(And(p([x,class_s2]),p([x,class_rstos0])))),\n",
    "#         Forall(x,Not(And(p([x,class_s2]),p([x,class_oth])))),\n",
    "#         Forall(x,Not(And(p([x,class_s2]),p([x,class_sh])))),\n",
    "        \n",
    "#         Forall(x,Not(And(p([x,class_s0]),p([x,class_s3])))),\n",
    "#         Forall(x,Not(And(p([x,class_s0]),p([x,class_rsto])))),\n",
    "#         Forall(x,Not(And(p([x,class_s0]),p([x,class_rstr])))),\n",
    "#         Forall(x,Not(And(p([x,class_s0]),p([x,class_rstos0])))),\n",
    "#         Forall(x,Not(And(p([x,class_s0]),p([x,class_oth])))),\n",
    "#         Forall(x,Not(And(p([x,class_s0]),p([x,class_sh])))),\n",
    "        \n",
    "#         Forall(x,Not(And(p([x,class_s3]),p([x,class_rsto])))),\n",
    "#         Forall(x,Not(And(p([x,class_s3]),p([x,class_rstr])))),\n",
    "#         Forall(x,Not(And(p([x,class_s3]),p([x,class_rstos0])))),\n",
    "#         Forall(x,Not(And(p([x,class_s3]),p([x,class_oth])))),\n",
    "#         Forall(x,Not(And(p([x,class_s3]),p([x,class_sh])))),\n",
    "        \n",
    "#         Forall(x,Not(And(p([x,class_rsto]),p([x,class_rstr])))),\n",
    "#         Forall(x,Not(And(p([x,class_rsto]),p([x,class_rstos0])))),\n",
    "#         Forall(x,Not(And(p([x,class_rsto]),p([x,class_oth])))),\n",
    "#         Forall(x,Not(And(p([x,class_rsto]),p([x,class_sh])))),\n",
    "        \n",
    "#         Forall(x,Not(And(p([x,class_rstr]),p([x,class_rstos0])))),\n",
    "#         Forall(x,Not(And(p([x,class_rstr]),p([x,class_oth])))),\n",
    "#         Forall(x,Not(And(p([x,class_rstr]),p([x,class_sh])))),\n",
    "        \n",
    "#         Forall(x,Not(And(p([x,class_rstos0]),p([x,class_oth])))),\n",
    "#         Forall(x,Not(And(p([x,class_rstos0]),p([x,class_sh])))),\n",
    "        \n",
    "#         Forall(x,Not(And(p([x,class_oth]),p([x,class_sh])))),\n",
    "    ]\n",
    "    sat_level = formula_aggregator(axioms).tensor\n",
    "    return sat_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83aabb19-155c-4f10-8a58-f87747eb7978",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 21:40:06.198227: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-01-25 21:40:06.198551: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial sat level 0.33618\n"
     ]
    }
   ],
   "source": [
    "for features, label_protocol_type, label_flag in ds_train:\n",
    "    print(\"Initial sat level %.5f\"%axioms(features,label_protocol_type,label_flag))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cdd35a-fe99-4d93-bf0d-9dace145880a",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0f3618d-ddea-433f-a6a6-5875a55d8ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = {\n",
    "    'train_sat_kb': tf.keras.metrics.Mean(name='train_sat_kb'),\n",
    "    'test_sat_kb': tf.keras.metrics.Mean(name='test_sat_kb'),\n",
    "    'train_accuracy': tf.keras.metrics.Mean(name=\"train_accuracy\"),\n",
    "    'test_accuracy': tf.keras.metrics.Mean(name=\"test_accuracy\"),\n",
    "    'test_sat_phi1': tf.keras.metrics.Mean(name='test_sat_phi1'),\n",
    "    'test_sat_phi2': tf.keras.metrics.Mean(name='test_sat_phi2'),\n",
    "    'test_sat_phi3': tf.keras.metrics.Mean(name='test_sat_phi3')\n",
    "}\n",
    "\n",
    "@tf.function()\n",
    "def sat_phi1(features):\n",
    "    x = ltn.Variable(\"x\",features)\n",
    "    phi1 = Forall(x, Implies(p([x,class_udp]),Not(p([x,class_tcp]))),p=5)\n",
    "    return phi1.tensor\n",
    "\n",
    "@tf.function()\n",
    "def sat_phi2(features):\n",
    "    x = ltn.Variable(\"x\",features)\n",
    "    phi2 = Forall(x, Implies(p([x,class_udp]),p([x,class_tcp])),p=5)\n",
    "    return phi2.tensor\n",
    "\n",
    "@tf.function()\n",
    "def sat_phi3(features):\n",
    "    x = ltn.Variable(\"x\",features)\n",
    "    phi3 = Forall(x, Implies(p([x,class_tcp]),p([x,class_sf])),p=5)\n",
    "    return phi3.tensor\n",
    "\n",
    "def multilabel_hamming_loss(y_true, y_pred, threshold=0.5,from_logits=False):\n",
    "    if from_logits:\n",
    "        y_pred = tf.math.sigmoid(y_pred)\n",
    "    y_pred = y_pred > threshold\n",
    "    y_true = tf.cast(y_true, tf.int32)\n",
    "    y_pred = tf.cast(y_pred, tf.int32)\n",
    "    nonzero = tf.cast(tf.math.count_nonzero(y_true-y_pred,axis=-1),tf.float32)\n",
    "    return nonzero/y_true.get_shape()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29091238-591b-45fd-954c-33252dfb1381",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "@tf.function\n",
    "def train_step(features, label_protocol_type, label_flag):\n",
    "    # sat and update\n",
    "    with tf.GradientTape() as tape:\n",
    "        sat = axioms(features, label_protocol_type, label_flag)\n",
    "        loss = 1.-sat\n",
    "    gradients = tape.gradient(loss, p.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, p.trainable_variables))\n",
    "    metrics_dict['train_sat_kb'](sat)\n",
    "    # accuracy\n",
    "    predictions = logits_model(features)\n",
    "    label_tcp = (label_protocol_type == \"TCP\")\n",
    "    label_icmp = (label_protocol_type == \"ICMP\")\n",
    "    label_udp = (label_protocol_type == \"UDP\")\n",
    "    label_sf = (label_flag == \"SF\")\n",
    "    label_s1 = (label_flag == \"S1\")\n",
    "    label_rej = (label_flag == \"REJ\")\n",
    "    label_s2 = (label_flag == \"S2\")\n",
    "    label_s0 = (label_flag == \"S0\")\n",
    "    label_s3 = (label_flag == \"S3\")\n",
    "    label_rsto = (label_flag == \"RSTO\")\n",
    "    label_rstr = (label_flag == \"RSTR\")\n",
    "    label_rstos0 = (label_flag == \"RSTOS0\")\n",
    "    label_oth = (label_flag == \"OTH\")\n",
    "    label_sh = (label_flag == \"SH\")\n",
    "    \n",
    "\n",
    "    onehot = tf.stack([label_tcp,label_icmp,label_udp,label_sf,label_s1,label_rej,label_s2,label_s0,label_s3,label_rsto,label_rstr,label_rstos0,label_oth,label_sh],axis=-1)\n",
    "    #onehot = tf.stack([label_tcp,label_icmp,label_udp,label_sf],axis=-1)\n",
    "    metrics_dict['train_accuracy'](1-multilabel_hamming_loss(onehot,predictions,from_logits=True))\n",
    "    \n",
    "@tf.function\n",
    "def test_step(features, label_protocol_type, label_flag):\n",
    "    # sat\n",
    "    sat_kb = axioms(features, label_protocol_type, label_flag)\n",
    "    metrics_dict['test_sat_kb'](sat_kb)\n",
    "    metrics_dict['test_sat_phi1'](sat_phi1(features))\n",
    "    metrics_dict['test_sat_phi2'](sat_phi2(features))\n",
    "    metrics_dict['test_sat_phi3'](sat_phi3(features))\n",
    "    # accuracy\n",
    "    predictions = logits_model(features)\n",
    "    label_tcp = (label_protocol_type == \"TCP\")\n",
    "    label_icmp = (label_protocol_type == \"ICMP\")\n",
    "    label_udp = (label_protocol_type == \"UDP\")\n",
    "    label_sf = (label_flag == \"SF\")\n",
    "    label_s1 = (label_flag == \"S1\")\n",
    "    label_rej = (label_flag == \"REJ\")\n",
    "    label_s2 = (label_flag == \"S2\")\n",
    "    label_s0 = (label_flag == \"S0\")\n",
    "    label_s3 = (label_flag == \"S3\")\n",
    "    label_rsto = (label_flag == \"RSTO\")\n",
    "    label_rstr = (label_flag == \"RSTR\")\n",
    "    label_rstos0 = (label_flag == \"RSTOS0\")\n",
    "    label_oth = (label_flag == \"OTH\")\n",
    "    label_sh = (label_flag == \"SH\")\n",
    "    onehot = tf.stack([label_tcp,label_icmp,label_udp,label_sf,label_s1,label_rej,label_s2,label_s0,label_s3,label_rsto,label_rstr,label_rstos0,label_oth,label_sh],axis=-1)\n",
    "    #onehot = tf.stack([label_tcp,label_icmp,label_udp,label_sf],axis=-1)\n",
    "    metrics_dict['test_accuracy'](1-multilabel_hamming_loss(onehot,predictions,from_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d8861a1-1a0e-4e9d-b4eb-5447da40c483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def train(\n",
    "        epochs,\n",
    "        metrics_dict, \n",
    "        ds_train, \n",
    "        ds_test, \n",
    "        train_step, \n",
    "        test_step,\n",
    "        track_metrics=1,\n",
    "        csv_path=None,\n",
    "        scheduled_parameters=defaultdict(lambda : {})\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        epochs: int, number of training epochs.\n",
    "        metrics_dict: dict, {\"metrics_label\": tf.keras.metrics instance}.\n",
    "        ds_train: iterable dataset, e.g. using tf.data.Dataset.\n",
    "        ds_test: iterable dataset, e.g. using tf.data.Dataset.\n",
    "        train_step: callable function. the arguments passed to the function\n",
    "            are the itered elements of ds_train.\n",
    "        test_step: callable function. the arguments passed to the function\n",
    "            are the itered elements of ds_test.\n",
    "        csv_path: (optional) path to create a csv file, to save the metrics.\n",
    "        scheduled_parameters: (optional) a dictionary that returns kwargs for\n",
    "            the train_step and test_step functions, for each epoch.\n",
    "            Call using scheduled_parameters[epoch].\n",
    "    \"\"\"\n",
    "    template = \"Epoch {}\"\n",
    "    for metrics_label in metrics_dict.keys():\n",
    "        template += \", %s: {:.4f}\" % metrics_label\n",
    "    if csv_path is not None:\n",
    "        csv_file = open(csv_path,\"w+\")\n",
    "        headers = \",\".join([\"Epoch\"]+list(metrics_dict.keys()))\n",
    "        csv_template = \",\".join([\"{}\" for _ in range(len(metrics_dict)+1)])\n",
    "        csv_file.write(headers+\"\\n\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for metrics in metrics_dict.values():\n",
    "            metrics.reset_states()\n",
    "\n",
    "        for batch_elements in ds_train:\n",
    "            train_step(*batch_elements,**scheduled_parameters[epoch])\n",
    "        for batch_elements in ds_test:\n",
    "            test_step(*batch_elements,**scheduled_parameters[epoch])\n",
    "\n",
    "        metrics_results = [metrics.result() for metrics in metrics_dict.values()]\n",
    "        if epoch%track_metrics == 0:\n",
    "            print(template.format(epoch,*metrics_results))\n",
    "        if csv_path is not None:\n",
    "            csv_file.write(csv_template.format(epoch,*metrics_results)+\"\\n\")\n",
    "            csv_file.flush()\n",
    "    if csv_path is not None:\n",
    "        csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec5172a5-8eeb-40a9-831a-763e46d3cd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 21:40:07.122021: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-25 21:41:34.089791: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-25 21:41:45.302566: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train_sat_kb: 0.8647, test_sat_kb: 0.9738, train_accuracy: 0.4954, test_accuracy: 0.5004, test_sat_phi1: 0.9999, test_sat_phi2: 0.9998, test_sat_phi3: 0.9999\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "train(\n",
    "    EPOCHS,\n",
    "    metrics_dict,\n",
    "    ds_train,\n",
    "    ds_test,\n",
    "    train_step,\n",
    "    test_step,\n",
    "    csv_path=\"results.csv\",\n",
    "    track_metrics=20\n",
    ")\n",
    "\n",
    "end_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9964a478-17d7-4fb4-b4eb-af4a8c62d3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 2023.613s to run\n"
     ]
    }
   ],
   "source": [
    "print(\"It took\", end =\" \")\n",
    "total_time = round(end_time-start_time,3)\n",
    "print(total_time , end =\"\")\n",
    "print(\"s to run\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
